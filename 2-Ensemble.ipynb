{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toponym Interlinking via Ensemble methods\n",
    "\n",
    "This notebook combines the following approaches via simple averaging and stacking in order to improve the accuracy of the toponym interlinking task:\n",
    "- BERT model, as implemented in the notebook \"1-BERT.ipynb\"\n",
    "- String Similarity-based features, as implemented in https://github.com/LinkGeoML/LGM-Interlinking and utilized to train a Random Forest classifier\n",
    "- Siamese RNN, as implemented in https://github.com/LuisPB7/StringMatching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train, val and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances: 1999994\n",
      "Number of val instances: 499999\n",
      "Number of test instances: 2499991\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "val_df = pd.read_csv('data/val.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_labels = train_df['label']\n",
    "val_labels = val_df['label']\n",
    "test_labels = test_df['label']\n",
    "\n",
    "print('Number of train instances:', train_df.shape[0])\n",
    "print('Number of val instances:', val_df.shape[0])\n",
    "print('Number of test instances:', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "Load the BERT predictions created by the code in \"1-BERT.ipynb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499999, 2) (2499991, 2)\n"
     ]
    }
   ],
   "source": [
    "bert_val_preds = np.load('preds/bert_val_preds.npy')\n",
    "bert_test_preds = np.load('preds/bert_test_preds.npy')\n",
    "\n",
    "print(bert_val_preds.shape, bert_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.8867977735955472\n",
      "Test accuracy: 0.8869371929738947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Val accuracy:', accuracy_score(val_labels, np.argmax(bert_val_preds, axis=1)))\n",
    "print('Test accuracy:', accuracy_score(test_labels, np.argmax(bert_test_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity-ML\n",
    "\n",
    "Code to create the features defined in https://github.com/LinkGeoML/LGM-Interlinking \n",
    "\n",
    "Repository's code is minimally adapted in order to make the following snippet work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1999994, 43), (499999, 43), (2499991, 43))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LGM_Interlinking.interlinking.helpers import StaticValues\n",
    "from LGM_Interlinking.interlinking import pre_process\n",
    "from LGM_Interlinking.interlinking.sim_measures import LGMSimVars\n",
    "from LGM_Interlinking.interlinking.features import Features\n",
    "\n",
    "encoding = 'global'\n",
    "LGMSimVars.per_metric_optValues = StaticValues.opt_values[encoding]\n",
    "pre_process.extract_freqterms('data/train.csv', encoding)\n",
    "\n",
    "train_feats = Features()\n",
    "train_feats.load_data('data/train.csv', encoding)\n",
    "train_feats = train_feats.build()\n",
    "\n",
    "val_feats = Features()\n",
    "val_feats.load_data('data/val.csv', encoding)\n",
    "val_feats = val_feats.build()\n",
    "\n",
    "test_feats = Features()\n",
    "test_feats.load_data('data/test.csv', encoding)\n",
    "test_feats = test_feats.build()\n",
    "\n",
    "train_feats.shape, val_feats.shape, test_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Random Forest classifier. Predict on val and test sets and save the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(train_feats, train_labels)\n",
    "\n",
    "rf_val_preds = rf.predict_proba(val_feats)\n",
    "rf_test_preds = rf.predict_proba(test_feats)\n",
    "\n",
    "np.save('preds/rf_val_preds.npy', rf_val_preds)\n",
    "np.save('preds/rf_test_preds.npy', rf_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.8598177196354393\n",
      "Test accuracy: 0.8602514969053888\n"
     ]
    }
   ],
   "source": [
    "print('Val accuracy:', accuracy_score(val_labels, np.argmax(rf_val_preds, axis=1)))\n",
    "print('Test accuracy:', accuracy_score(test_labels, np.argmax(rf_test_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese-RNN\n",
    "\n",
    "Code to create the features defined in https://github.com/LuisPB7/StringMatching\n",
    "\n",
    "Repository's code is minimally adapted in order to make the following snippet work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:gpu available: True, used: True\n",
      "INFO:root:VISIBLE GPUS: 0\n",
      "INFO:root:\n",
      "              Name     Type Params\n",
      "0             lin1   Linear   28 K\n",
      "1             lin2   Linear   61  \n",
      "2             relu     ReLU    0  \n",
      "3          dropout  Dropout    0  \n",
      "4          sigmoid  Sigmoid    0  \n",
      "5          Encoder  Encoder  158 K\n",
      "6  Encoder.dropout  Dropout    0  \n",
      "7     Encoder.relu     ReLU    0  \n",
      "8     Encoder.gru1      GRU   92 K\n",
      "9     Encoder.gru2      GRU   65 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 7813/7813 [06:16<00:00, 21.21batch/s, batch_idx=7812, gpu=0, loss=0.243, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 7813/7813 [06:17<00:00, 20.71batch/s, batch_idx=7812, gpu=0, loss=0.243, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "              Name     Type Params\n",
      "0             lin1   Linear   28 K\n",
      "1             lin2   Linear   61  \n",
      "2             relu     ReLU    0  \n",
      "3          dropout  Dropout    0  \n",
      "4          sigmoid  Sigmoid    0  \n",
      "5          Encoder  Encoder  158 K\n",
      "6  Encoder.dropout  Dropout    0  \n",
      "7     Encoder.relu     ReLU    0  \n",
      "8     Encoder.gru1      GRU   92 K\n",
      "9     Encoder.gru2      GRU   65 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing: 100%|██████████| 1954/1954 [01:10<00:00, 27.53batch/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      "              Name     Type Params\n",
      "0             lin1   Linear   28 K\n",
      "1             lin2   Linear   61  \n",
      "2             relu     ReLU    0  \n",
      "3          dropout  Dropout    0  \n",
      "4          sigmoid  Sigmoid    0  \n",
      "5          Encoder  Encoder  158 K\n",
      "6  Encoder.dropout  Dropout    0  \n",
      "7     Encoder.relu     ReLU    0  \n",
      "8     Encoder.gru1      GRU   92 K\n",
      "9     Encoder.gru2      GRU   65 K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 9766/9766 [05:48<00:00, 28.02batch/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from StringMatching.RSModel import RSModel\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = RSModel('rs', 'train', 'val')\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=0.00,\n",
    "    patience=3,\n",
    "    verbose=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "trainer = Trainer(gpus=1, show_progress_bar=True,\n",
    "                  max_nb_epochs=20, early_stop_callback=early_stop_callback)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(os.getcwd(), 'StringMatching/weights/rs-train.pt')), strict=True)\n",
    "    print(\"Successfully loaded weights\")\n",
    "except:\n",
    "    trainer.fit(model)\n",
    "trainer.test(model)\n",
    "\n",
    "\n",
    "model = RSModel('rs', 'train', 'test')\n",
    "model.load_state_dict(torch.load(os.path.join(os.getcwd(), 'StringMatching/weights/rs-train.pt')), strict=True)\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the corresponding predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499999, 1) (2499991, 1)\n"
     ]
    }
   ],
   "source": [
    "rs_val_preds = np.load('preds/rs_val_preds.npy')\n",
    "rs_test_preds = np.load('preds/rs_test_preds.npy')\n",
    "\n",
    "print(rs_val_preds.shape, rs_test_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model's predictions contain only 1 number per sample, this cell just transforms these predictions in order to follow the format of the first 2 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499999, 2) (2499991, 2)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(rs_val_preds.shape)\n",
    "for ii, i in enumerate(rs_val_preds):\n",
    "    a[ii] = 1-i\n",
    "rs_val_preds = np.hstack([a, rs_val_preds])\n",
    "np.save('preds/rs_val_preds.npy', rs_val_preds)\n",
    "\n",
    "a = np.zeros(rs_test_preds.shape)\n",
    "for ii, i in enumerate(rs_test_preds):\n",
    "    a[ii] = 1-i\n",
    "rs_test_preds = np.hstack([a, rs_test_preds])\n",
    "np.save('preds/rs_test_preds.npy', rs_test_preds)\n",
    "\n",
    "print(rs_val_preds.shape, rs_test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 0.8917057834115668\n",
      "Test accuracy: 0.8916136098089953\n"
     ]
    }
   ],
   "source": [
    "print('Val accuracy:', accuracy_score(val_labels, np.argmax(rs_val_preds, axis=1)))\n",
    "print('Test accuracy:', accuracy_score(test_labels, np.argmax(rs_test_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging\n",
    "\n",
    "Search for the best weights to use while averaging the 3 models predictions on the val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.15000000000000002, 0.35000000000000003, 0.5), 0.9073398146796293)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "weights = [p for p in product(np.arange(0.0, 1.05, 0.05), repeat=3) if sum(p) == 1.0]\n",
    "best_weights, best_acc = None, 0\n",
    "\n",
    "for w in weights:\n",
    "    val_preds = np.average([bert_val_preds, rf_val_preds, rs_val_preds], axis=0, weights=w)\n",
    "    acc = accuracy_score(val_labels, np.argmax(val_preds, axis=1))\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_weights = w\n",
    "\n",
    "best_weights, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best weights to evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9073948666215198\n"
     ]
    }
   ],
   "source": [
    "test_preds = np.average([bert_test_preds, rf_test_preds, rs_test_preds], axis=0, weights=best_weights)\n",
    "print('Test accuracy:', accuracy_score(test_labels, np.argmax(test_preds, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "Stack the val predictions of the 3 models to train MLP as a 'meta-classifier'. Evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9082272696181706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "val_preds = np.hstack([bert_val_preds, rf_val_preds, rs_val_preds])\n",
    "test_preds = np.hstack([bert_test_preds, rf_test_preds, rs_test_preds])\n",
    "\n",
    "mlp = MLPClassifier(learning_rate='adaptive').fit(val_preds, val_labels)\n",
    "preds = mlp.predict(test_preds)\n",
    "print('Test accuracy:', accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToponymMatchingEnv",
   "language": "python",
   "name": "toponymmatchingenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
