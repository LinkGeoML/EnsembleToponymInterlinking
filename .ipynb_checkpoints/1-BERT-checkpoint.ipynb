{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toponym Interlinking using Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset files. Split to train, val and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train instances: 1999994\n",
      "Number of val instances: 499999\n",
      "Number of test instances: 2499991\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_csv = 'data/geonames_1.csv'\n",
    "test_csv = 'data/geonames_2.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_csv, delimiter='|', names=['s1', 's2', 'label'])\n",
    "train_df = train_df.dropna().reset_index(drop=True)\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=2020)\n",
    "\n",
    "test_df = pd.read_csv(test_csv, delimiter='|', names=['s1', 's2', 'label'])\n",
    "test_df = test_df.dropna().reset_index(drop=True)\n",
    "\n",
    "print('Number of train instances:', train_df.shape[0])\n",
    "print('Number of val instances:', val_df.shape[0])\n",
    "print('Number of test instances:', test_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save specific datasets in order to use them with the rest of approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train.csv', index=False)\n",
    "val_df.to_csv('data/val.csv', index=False)\n",
    "test_df.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract pair instances as well as their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[['s1', 's2']].values\n",
    "val_texts = val_df[['s1', 's2']].values\n",
    "test_texts = test_df[['s1', 's2']].values\n",
    "\n",
    "train_labels = train_df['label'].values\n",
    "val_labels = val_df['label'].values\n",
    "test_labels = test_df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode toponym pairs using BertTokenizer. This will create the necessary components in order to be used as input to the Bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "train_encoded_dict = [tokenizer.encode_plus(text=text1, text_pair=text2, max_length=128, pad_to_max_length=True)\n",
    "                      for text1, text2 in train_texts]\n",
    "val_encoded_dict = [tokenizer.encode_plus(text=text1, text_pair=text2, max_length=128, pad_to_max_length=True)\n",
    "                    for text1, text2 in val_texts]\n",
    "test_encoded_dict = [tokenizer.encode_plus(text=text1, text_pair=text2, max_length=128, pad_to_max_length=True)\n",
    "                     for text1, text2 in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids = [d['input_ids'] for d in train_encoded_dict]\n",
    "train_token_type_ids = [d['token_type_ids'] for d in train_encoded_dict]\n",
    "train_attention_masks = [d['attention_mask'] for d in train_encoded_dict]\n",
    "\n",
    "val_input_ids = [d['input_ids'] for d in val_encoded_dict]\n",
    "val_token_type_ids = [d['token_type_ids'] for d in val_encoded_dict]\n",
    "val_attention_masks = [d['attention_mask'] for d in val_encoded_dict]\n",
    "\n",
    "test_input_ids = [d['input_ids'] for d in test_encoded_dict]\n",
    "test_token_type_ids = [d['token_type_ids'] for d in test_encoded_dict]\n",
    "test_attention_masks = [d['attention_mask'] for d in test_encoded_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_input_ids = torch.tensor(train_input_ids)\n",
    "train_token_type_ids = torch.tensor(train_token_type_ids)\n",
    "train_attention_masks = torch.tensor(train_attention_masks)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n",
    "val_input_ids = torch.tensor(val_input_ids)\n",
    "val_token_type_ids = torch.tensor(val_token_type_ids)\n",
    "val_attention_masks = torch.tensor(val_attention_masks)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "\n",
    "test_input_ids = torch.tensor(test_input_ids)\n",
    "test_token_type_ids = torch.tensor(test_token_type_ids)\n",
    "test_attention_masks = torch.tensor(test_attention_masks)\n",
    "test_labels = torch.tensor(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_data = TensorDataset(train_input_ids, train_token_type_ids, train_attention_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "val_data = TensorDataset(val_input_ids, val_token_type_ids, val_attention_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "test_data = TensorDataset(test_input_ids, test_token_type_ids, test_attention_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition. We will use BertForSequenceClassification to carry out the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AdamW\n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "loss_func.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "epochs = 4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use seed to make the experiment reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed_val = 2020\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_token_type_ids = batch[1].to(device)\n",
    "        b_attention_masks = batch[2].to(device)\n",
    "        b_labels = batch[3].to(device)\n",
    "        model.zero_grad()        \n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids,\n",
    "                        attention_mask=b_attention_masks, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    avg_train_loss = total_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run val data though the trained model to extract predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_preds, val_true_labels = [], []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_token_type_ids, b_attention_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids,\n",
    "                        attention_mask=b_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    val_preds.append(logits)\n",
    "    val_true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save val predictions in order to use them in the ensemble methods. Calculate val accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "val_preds = [item for sublist in val_preds for item in sublist]\n",
    "np.save('preds/bert_val_preds.npy', np.array(val_preds))\n",
    "val_preds = np.argmax(val_preds, axis=1).flatten()\n",
    "val_true_labels = [item for sublist in val_true_labels for item in sublist]\n",
    "\n",
    "val_acc = accuracy_score(val_true_labels, val_preds)\n",
    "\n",
    "print('Validation Accuracy: %.3f' % val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run test data through the trained model to extract predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_true_labels = [], []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_token_type_ids, b_attention_masks, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_type_ids,\n",
    "                        attention_mask=b_attention_masks)\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    test_preds.append(logits)\n",
    "    test_true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save test predictions in order to use them in the ensemble methods. Calculate test accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [item for sublist in test_preds for item in sublist]\n",
    "np.save('preds/bert_test_preds.npy', np.array(test_preds))\n",
    "test_preds = np.argmax(test_preds, axis=1).flatten()\n",
    "test_true_labels = [item for sublist in test_true_labels for item in sublist]\n",
    "\n",
    "test_acc = accuracy_score(test_true_labels, test_preds)\n",
    "\n",
    "print('Test Accuracy: %.3f' % test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ToponymMatchingEnv",
   "language": "python",
   "name": "toponymmatchingenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
